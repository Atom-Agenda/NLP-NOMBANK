{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PglZHV2iEZ5w"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import *\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "POS_DICT = []\n",
        "BIO_DICT = []\n",
        "PATH_DICT = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ssTXJd6EsxW",
        "outputId": "73a31187-5f0c-4d6e-ef31-91fd00f805ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def index_list(dict, key):\n",
        "    if key in dict:\n",
        "        return dict.index(key)\n",
        "    else:\n",
        "        dict.append(key)\n",
        "        return dict.index(key)"
      ],
      "metadata": {
        "id": "bQM4cfGWFAFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(pth):\n",
        "    pairs_data = []\n",
        "    sentence = []\n",
        "    with open(pth, 'r') as file:\n",
        "        lines_in = file.read().split('\\n')\n",
        "        for line in lines_in:\n",
        "            if line == '':\n",
        "                if sentence == '' or len(sentence) < 3:\n",
        "                    sentence = []\n",
        "                    continue\n",
        "                # print(\"s\", sentence)\n",
        "                pairs_data += find_pair(sentence)\n",
        "                sentence = []\n",
        "                continue\n",
        "            else:\n",
        "                sentence.append(line)\n",
        "    # print(\"pairs_data\", pairs_data)\n",
        "    if len(sentence)>0 : \n",
        "      pairs_data += find_pair(sentence)\n",
        "    print(\"pair_data size path \",pth, len(pairs_data))\n",
        "    return pairs_data"
      ],
      "metadata": {
        "id": "BbrmZUuGFFkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pair(sentence):\n",
        "    pairs_data = []\n",
        "    whole_POS_path = []\n",
        "    whole_BIO_path = [] # ------TODO: introduce BIO path-------\n",
        "    for i, word in enumerate(sentence):\n",
        "        data = word.split('\\t')\n",
        "        whole_POS_path.append(data[1])\n",
        "        whole_BIO_path.append(data[2])\n",
        "        if len(data) < 6:\n",
        "            continue\n",
        "        if data[5] == \"ARG1\":\n",
        "            ARG_POS = data[1]\n",
        "            ARG_BIO = data[2]\n",
        "            ARG_num = data[3]\n",
        "\n",
        "        elif data[5] == \"PRED\":\n",
        "            PRED_POS = data[1]\n",
        "            PRED_BIO = data[2]\n",
        "            PRED_num = data[3]\n",
        "            PRED_index = i\n",
        "\n",
        "    for i, word in enumerate(sentence):\n",
        "        data = word.split('\\t')\n",
        "        if i == PRED_index:\n",
        "            continue\n",
        "        if i < PRED_index:\n",
        "            current_path = [whole_POS_path[x] for x in range(i, PRED_index+1)]\n",
        "        else:\n",
        "            current_path = [whole_POS_path[x] for x in range(PRED_index, i+1)]\n",
        "        current_path = ','.join(current_path)\n",
        "        if len(data) == 6 and data[5] == \"ARG1\":\n",
        "            role = 1\n",
        "        else:\n",
        "            role = 0\n",
        "        pairs_data.append([index_list(POS_DICT, PRED_POS)] + [index_list(BIO_DICT, PRED_BIO)]\n",
        "                          + [index_list(POS_DICT, data[1])] + [index_list(BIO_DICT, data[2])]\n",
        "                          + [int(PRED_num) - int(data[3])] + [index_list(PATH_DICT, current_path)]\n",
        "                          + [role])\n",
        "    return pairs_data"
      ],
      "metadata": {
        "id": "jLGQBoacFI4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    data_dir = Path(\"/content/drive/MyDrive/NLP 2022/nombank_train_dev_test/percentage\")\n",
        "    data_dir2 = Path(\"/content/drive/MyDrive/NLP 2022/Results\")\n",
        "    train_data_path = data_dir / 'train.data'\n",
        "    valid_data_path = data_dir / 'dev.data'\n",
        "    test_data_path = data_dir / 'test.data'\n",
        "    output_path = data_dir2 / 'RF_PPB.txt'\n",
        "    \n",
        "    pair_train = np.array(read_data(train_data_path))# loaded by function \"read_data\"\n",
        "    x = pair_train[:, 0:-1]\n",
        "    y = pair_train[:, -1]\n",
        "\n",
        "    # pair_test = onehot_pair(np.load(\"dev.npy\"), withpth=0)\n",
        "    pair_test = np.array(read_data(test_data_path))\n",
        "    x_test = pair_test[:, 0:-1]\n",
        "    y_test = pair_test[:, -1]\n",
        "\n",
        "    print(\"training DT\")\n",
        "    clf = RandomForestClassifier(n_estimators=200, criterion=\"gini\", min_samples_split=10, max_features=\"auto\", n_jobs=4)  \n",
        "    clf.fit(x, y)  \n",
        "    y_pred_DT = clf.predict(x_test) \n",
        "    print(\"confusion_matrix\", confusion_matrix(y_test, y_pred_DT))\n",
        "    print(\"accuracy_score\", accuracy_score(y_test,y_pred_DT))\n",
        "\n",
        "    N = 0\n",
        "    \n",
        "    with open(test_data_path, 'r') as file_in:\n",
        "        with open(output_path, 'w') as file_out:\n",
        "            lines_in = file_in.read().split('\\n')\n",
        "            #print(\"total no of lines is \", test_data_path,len(lines_in))\n",
        "            #C=0\n",
        "            for line in lines_in:\n",
        "                #print(\"processing line number : \",C)\n",
        "                data = line.split(\"\\t\")\n",
        "                if line == '' or len(line) <3:\n",
        "                    file_out.write(\"\\n\")\n",
        "                    continue\n",
        "                if len(data) >= 6 and data[5] == \"PRED\":\n",
        "                    file_out.write(line + \"\\n\")\n",
        "                    continue\n",
        "                if len(data) < 6:\n",
        "                    data.append(\"\")\n",
        "                if y_pred_DT[N] == 1:\n",
        "                    data[5] = \"ARG1\"\n",
        "                    N+=1\n",
        "                else:\n",
        "                    data[5] = \"\"\n",
        "                    N+=1\n",
        "                \n",
        "                file_out.write(\"\\t\".join(data) + \"\\n\")\n",
        "            \n",
        "            print(N)\n",
        "    assert N == len(y_pred_DT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_5KGAhFKQY",
        "outputId": "896af7aa-ed89-48b3-c20c-f6d4cabb2722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pair_data size path  /content/drive/MyDrive/NLP 2022/nombank_train_dev_test/percentage/train.data 59555\n",
            "pair_data size path  /content/drive/MyDrive/NLP 2022/nombank_train_dev_test/percentage/test.data 4128\n",
            "training DT\n",
            "confusion_matrix [[3932   45]\n",
            " [  99   52]]\n",
            "accuracy_score 0.9651162790697675\n",
            "4128\n"
          ]
        }
      ]
    }
  ]
}